{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loose-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import spacy\n",
    "import benepar\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tempfile import TemporaryDirectory\n",
    "from fairseq.models.bart import BARTModel\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tree import Tree\n",
    "from nltk.tree import ParentedTree\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "\n",
    "from transformers.pipelines import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#from bert_score import BERTScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "friendly-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEQA(object):\n",
    "    def __init__(self, device='cpu', qa_model_name = \"deepset/minilm-uncased-squad2\", qg_model_dir='../feqa/bart_qg/checkpoints/'):\n",
    "        \n",
    "        self.qg_model = BARTModel.from_pretrained(\n",
    "            qg_model_dir,\n",
    "            checkpoint_file = 'checkpoint_best.pt'\n",
    "            )\n",
    "\n",
    "        if device=='cuda':\n",
    "            self.qg_model.to(device) #.cuda()\n",
    "            self.qg_model.half()\n",
    "        self.qg_model.eval()\n",
    "\n",
    "        self.batch_size = 1#64\n",
    "        self.beam_size = 10\n",
    "        self.max_length = 100\n",
    "\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        #self.parser = benepar.Parser(\"benepar_en2\")\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        self.qa_threshold = 0.1 # below threshold, the question quality is too vague\n",
    "        self.qa_pipeline = pipeline('question-answering', model=qa_model_name, tokenizer=qa_model_name)\n",
    "        \n",
    "    #    self.bertscorer = BERTScorer(lang=\"en\") #, rescale_with_baseline=True)\n",
    "\n",
    "    def _get_entities(self, output_summary):\n",
    "        entities = [X.text for X in self.nlp(output_summary).ents]\n",
    "        return entities\n",
    "\n",
    "\n",
    "    # def _get_masked_phrases(self, output_summary, phrase_types=[\"NP\"]):\n",
    "    #     masked_phrases = []\n",
    "    #     parse_tree = self.parser.parse(output_summary)\n",
    "    #     for subtree in parse_tree.subtrees():\n",
    "    #         phrases_list = [(subtree_.leaves(), subtree_.label()) for subtree_ in subtree if type(subtree_) == Tree and subtree_.label() in phrase_types]\n",
    "    #         for phrase_tuple in phrases_list:\n",
    "    #             phrase = phrase_tuple[0]\n",
    "    #             phrase_type = phrase_tuple[1]\n",
    "    #             phrase_text = \" \".join(phrase)\n",
    "    #             if len(phrase) > 0 and phrase_text not in self.stop_words:\n",
    "    #                 masked_phrases.append(phrase_text)\n",
    "       \n",
    "    #     return masked_phrases \n",
    "\n",
    "\n",
    "    def _generate_questions(self, summaries, entities=True, phrase_types=[\"NP\"]):\n",
    "        doc_ids = []\n",
    "        qa_masks = []\n",
    "        tokenized_phrases = []\n",
    "\n",
    "        for id_, summary in enumerate(summaries):\n",
    "            summary = summary.strip()\n",
    "            all_masked_phrases = []\n",
    "            if entities:\n",
    "                all_masked_phrases.extend(self._get_entities(summary))\n",
    "            # all_masked_phrases.extend(self._get_masked_phrases(summary,phrase_types))\n",
    "            all_masked_phrases = list(set(all_masked_phrases))\n",
    "\n",
    "            for i, masked_phrase in enumerate(all_masked_phrases):\n",
    "                tokenized_summary = \" \".join(nltk.word_tokenize(summary.lower()))\n",
    "                tokenized_phrase = \" \".join(nltk.word_tokenize(masked_phrase.lower()))\n",
    "\n",
    "                qa_masks.append(tokenized_summary + \" [SEP] \" + tokenized_phrase)\n",
    "                doc_ids.append(str(id_))\n",
    "                tokenized_phrases.append(tokenized_phrase)\n",
    "\n",
    "        questions = []\n",
    "        for i in range(0, len(qa_masks), self.batch_size):\n",
    "            batch = qa_masks[i:i + self.batch_size]\n",
    "            hypotheses = self.qg_model.sample(batch, beam=self.beam_size, lenpen=1.0, max_len_b=self.max_length, min_len=1, no_repeat_ngram_size=3)\n",
    "            questions.extend(hypotheses)\n",
    "\n",
    "\n",
    "        return doc_ids, questions, tokenized_phrases\n",
    "\n",
    "    def _convert_to_squad_format(self, gold_answers, questions, doc_ids, bodies):\n",
    "        squad_format = {\"data\":[]}\n",
    "        \n",
    "        id_questions=defaultdict(list)\n",
    "        id_gold_answers=defaultdict(str)\n",
    "\n",
    "        for idx in range(0,len(doc_ids)):\n",
    "            id_questions[doc_ids[idx].strip()].append((questions[idx], gold_answers[idx]))\n",
    "        \n",
    "        for idx in id_questions:\n",
    "            paragraphs = []\n",
    "            context = bodies[int(idx)].strip()\n",
    "\n",
    "            title = \"doc_\" + str(idx)\n",
    "            \n",
    "            questions_list_input=[]\n",
    "            for q_id, question in enumerate(id_questions[idx]):\n",
    "\n",
    "                gold_answer = question[1]\n",
    "                question_text = question[0]\n",
    "                answers_input = [{\"text\": gold_answer, \"answer_start\": 0}]\n",
    "                questions_input = {\n",
    "                                    \"question\": question_text, \n",
    "                                    \"answers\": answers_input, \n",
    "                                    \"id\": str(idx).strip() + \"-\" + str(q_id)\n",
    "                                    }\n",
    "                questions_list_input.append(questions_input) \n",
    "                id_gold_answers[questions_input[\"id\"]] = gold_answer      \n",
    "\n",
    "            \n",
    "            paragraphs.append({\"context\":\" \".join(nltk.word_tokenize(context)).lower(),\"qas\":questions_list_input})\n",
    "            squad_format[\"data\"].append({\"title\":title,\"paragraphs\":paragraphs})\n",
    "\n",
    "            \n",
    "        squad_format[\"version\"] = \"1.1\"\n",
    "        return id_gold_answers, squad_format\n",
    "    \n",
    "    def _answer_questions_by_context(self, squad_format):\n",
    "        id_answers=defaultdict(str)\n",
    "\n",
    "        for doc in squad_format['data']:\n",
    "            for para in doc['paragraphs']:\n",
    "                context = para['context']\n",
    "\n",
    "                for q in para['qas']:\n",
    "                    inputs = {\n",
    "                        'question': q['question'],\n",
    "                        'context': context\n",
    "                    }\n",
    "                    ret = self.qa_pipeline(inputs)\n",
    "                    id_answers[q[\"id\"]] = ret\n",
    "    #                 print(q['question'])\n",
    "    #                 print(ret)\n",
    "    #             print()\n",
    "        return id_answers\n",
    "\n",
    "    def _readable_qas_dict(self, doc_ids, questions, gold_answers, pred_dict, bodies):\n",
    "        qas_dict = defaultdict()\n",
    "        previous_doc_id = None\n",
    "\n",
    "        for idx, qa_id in enumerate(pred_dict):\n",
    "            qa_info = {\"question\": questions[idx], \n",
    "                       \"gold_ans\": gold_answers[idx], \n",
    "                       \"reply_ans\": pred_dict[qa_id][\"answer\"],\n",
    "                       \"reply_scr\": pred_dict[qa_id][\"score\"]}\n",
    "\n",
    "#             if qa_info[\"reply_scr\"] > self.qa_threshold:\n",
    "#                 cand =  [qa_info[\"reply_ans\"]]\n",
    "#                 ref  =  [qa_info['gold_ans']]\n",
    "#                 _, _, bert_f1 = self.bertscorer.score( cand, ref )\n",
    "#                 qa_info[\"bert_f1\"] = bert_f1.item()\n",
    "#                 doc_f1_list.append(qa_info[\"bert_f1\"])\n",
    "#             else:\n",
    "#                 qa_info[\"bert_f1\"] = None\n",
    "            \n",
    "            doc_id = doc_ids[idx].strip()\n",
    "            \n",
    "            if doc_id != previous_doc_id:\n",
    "#                 if previous_doc_id is not None:\n",
    "#                     if len(doc_f1_list) == 0:\n",
    "#                         qas_dict[previous_doc_id][\"doc_f1\"] = 0\n",
    "#                     else:\n",
    "#                         qas_dict[previous_doc_id][\"doc_f1\"] = np.mean(doc_f1_list)\n",
    "#                         doc_f1_list = []\n",
    "                \n",
    "                qas_dict[doc_id] = dict()\n",
    "                qas_dict[doc_id]['context'] = bodies[int(doc_id)]\n",
    "                qas_dict[doc_id]['qas'] = dict()\n",
    "                qas_dict[doc_id]['qas'][qa_id] = qa_info\n",
    "            else:\n",
    "                qas_dict[doc_id]['qas'][qa_id] = qa_info\n",
    "            previous_doc_id = doc_ids[idx]\n",
    "\n",
    "        return qas_dict\n",
    "    \n",
    "    def _compute_f1(self, a_gold, a_pred): # with word-overlap\n",
    "        gold_toks = nltk.word_tokenize(a_gold)\n",
    "        pred_toks = nltk.word_tokenize(a_pred)\n",
    "        common = Counter(gold_toks) & Counter(pred_toks)\n",
    "        num_same = sum(common.values())\n",
    "        if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "            return int(gold_toks == pred_toks)\n",
    "        if num_same == 0:\n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_toks)\n",
    "        recall = 1.0 * num_same / len(gold_toks)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    \n",
    "    def _compare_pred_gold(self, qas_dict, use_bertscr=True):\n",
    "        doc_f1_list = []\n",
    "        for doc_id in qas_dict:\n",
    "            for qa_id in qas_dict[doc_id]['qas']:\n",
    "                qa_info = qas_dict[doc_id]['qas'][qa_id]\n",
    "                if qa_info[\"reply_scr\"] > self.qa_threshold:\n",
    "                    cand =  qa_info[\"reply_ans\"]\n",
    "                    ref  =  qa_info['gold_ans']\n",
    "\n",
    "                    if use_bertscr:\n",
    "                        _, _, bert_f1 = self.bertscorer.score( [cand], [ref] )\n",
    "                        bert_f1 = bert_f1.item()\n",
    "                    else:\n",
    "                        bert_f1 = self._compute_f1(cand, ref)\n",
    "\n",
    "                    qas_dict[doc_id]['qas'][qa_id][\"bert_f1\"] = bert_f1\n",
    "                    doc_f1_list.append(qa_info[\"bert_f1\"])\n",
    "                else:\n",
    "                    qa_info[\"bert_f1\"] = None\n",
    "            \n",
    "            if len(doc_f1_list) == 0:\n",
    "                qas_dict[doc_id][\"doc_f1\"] = 0\n",
    "            else:\n",
    "                qas_dict[doc_id][\"doc_f1\"] = np.mean(doc_f1_list)\n",
    "            doc_f1_list = []\n",
    "        \n",
    "        f1_list = []\n",
    "        for doc_id in qas_dict:\n",
    "            f1_list.append(qas_dict[doc_id][\"doc_f1\"] )\n",
    "\n",
    "        return qas_dict, f1_list\n",
    "\n",
    "    def prevent_no_question_generate(self, summaries, doc_ids, f1_list):\n",
    "        expect_docs = len(summaries)\n",
    "        docs_with_score = list(set(doc_ids))\n",
    "\n",
    "        doc_with_f1 = list(set(doc_ids))\n",
    "        doc_with_f1.sort()\n",
    "\n",
    "        cnt = 0\n",
    "        true_f1_list = []\n",
    "        for i in range(expect_docs):\n",
    "            if str(i) not in docs_with_score:\n",
    "                true_f1_list.append(0)\n",
    "                cnt += 1\n",
    "            else:\n",
    "                target = i - cnt\n",
    "                true_f1_list.append(f1_list[target])\n",
    "        return true_f1_list\n",
    "        \n",
    "    \n",
    "    def compute_score(self, bodies, summaries, aggregate=False, show_qas_dict=False, use_bertscr=False):\n",
    "        #generate questions from summaries\n",
    "        #print(\"Generating questions...\")\n",
    "\n",
    "        ts = time.time()\n",
    "        doc_ids, questions, gold_answers = self._generate_questions(summaries)\n",
    "        te = time.time()\n",
    "        #print(\"time spent generate questions:\", te-ts)\n",
    "        print(doc_ids)\n",
    "\n",
    "        #print(\"Getting answers...\")\n",
    "        #run qa system\n",
    "        ts = time.time()\n",
    "        gold_answers_dict, squad_format = self._convert_to_squad_format(gold_answers, questions, doc_ids, bodies)\n",
    "        pred_dict = self._answer_questions_by_context(squad_format)\n",
    "\n",
    "        te = time.time()\n",
    "        #print(\"time spent answering questions:\", te-ts)\n",
    "        \n",
    "        qas_dict = self._readable_qas_dict(doc_ids, questions, gold_answers, pred_dict, bodies)\n",
    "        qas_dict, f1_list = self._compare_pred_gold(qas_dict, use_bertscr=use_bertscr)\n",
    "        f1_list = self.prevent_no_question_generate(summaries, doc_ids, f1_list)\n",
    "        \n",
    "        if show_qas_dict:\n",
    "            for doc_id in qas_dict:\n",
    "                #print(\"context:\", qas_dict[doc_id]['context'])\n",
    "                print(\"doc_f1:\", qas_dict[doc_id]['doc_f1'])\n",
    "                qas = qas_dict[doc_id]['qas']\n",
    "                for q_id in qas:\n",
    "                    print(q_id)\n",
    "                    print(\"qst:\", qas[q_id][\"question\"])\n",
    "                    print(\"g_a:\", qas[q_id][\"gold_ans\"])\n",
    "                    print(\"r_a:\", qas[q_id][\"reply_ans\"])\n",
    "                    print(\"scr:\", qas[q_id][\"reply_scr\"])\n",
    "                    print(\"bert_f1:\",  qas[q_id][\"bert_f1\"] )\n",
    "\n",
    "        if aggregate:\n",
    "            return np.mean(f1_list)\n",
    "        \n",
    "        return f1_list\n",
    "    \n",
    "    def score(self, summaries, bodies, bodies_tokenized=None, lengths=None, extra=None):\n",
    "        if extra is None: # sample_score\n",
    "            scores = self.compute_score( bodies, summaries, aggregate=False, show_qas_dict=False, use_bertscr=False)\n",
    "            return scores, \"no need to cal faithfulness for argmax\"\n",
    "        else: # argmax_scoreZ\n",
    "            scores = [0] * len(summaries)\n",
    "            return scores, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjustable-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = FEQA(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "             \"The world's oldest person has died a \\\n",
    "             few weeks after celebrating her 117th birthday.  \\\n",
    "             Born on March 5, 1898, the greatgrandmother had lived through two world \\\n",
    "             wars, the invention of the television and the \\\n",
    "             first successful powered aeroplane.\", \n",
    "            \"The world's oldest person has died a \\\n",
    "             few weeks after celebrating her 117th birthday.  \\\n",
    "             Born on March 5, 1898, the greatgrandmother had lived through two world \\\n",
    "             wars, the invention of the television and the \\\n",
    "             first successful powered aeroplane.\"]\n",
    "summaries = [\n",
    "             \"The world's oldest person died in 1898\",\n",
    "             \"The world's oldest person died after her 117th birthday\"]\n",
    "scorer.compute_score(documents, summaries, aggregate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-probability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary-loop",
   "language": "python",
   "name": "summary-loop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
